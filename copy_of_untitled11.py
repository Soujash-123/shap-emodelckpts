# -*- coding: utf-8 -*-
"""Copy of Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjvLwHo2LO3KW7ulThWIEF1l3jft4G3j
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/crockwell/Cap3D.git
# %cd Cap3D/text-to-3D/shap-e

!python --version

!pip install -e .
!pip install gradio

# Install gdown if not already installed
!pip install -q gdown

# Download the file using the file ID
!gdown --id 1GQOZFfAMJ4parzt6Amjvy-5Wzqb5CpxC --output myfile.zip

# Unzip the downloaded file
!unzip myfile.zip -d myfolder

!cp -r myfolder/fineTune/model_ckpts .
!rm -rf myfolder
!rm myfile.zip

import torch
from shap_e.models.download import load_model
import os

os.makedirs("fine_tuned_models",exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load full models (only once)
text_model = load_model("text300M", device=device)
transmitter = load_model("transmitter", device=device)

# Save their state_dicts
torch.save(text_model.state_dict(), "./fine_tuned_models/text300M_state.pth")
torch.save(transmitter.state_dict(), "./fine_tuned_models/transmitter_state.pth")

"""**No Need to Run this Cell**"""

# ==============================================================================
# Copyright (c) 2023 Tiange Luo, tiange.cs@gmail.com
# Last modified: September 20, 2023
#
# This code is licensed under the MIT License.
# ==============================================================================
import torch

from shap_e.diffusion.sample import sample_latents
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.models.download import load_model, load_config
from shap_e.util.notebooks import decode_latent_mesh
import os
import time
import random
from IPython import embed
import pickle
import pandas as pd

# ==== Set configuration variables directly ====
ckpt = 'shapE_finetuned_with_825kdata.pth'
save_name = 'Cap3D_test1_meshes'
test_type = '2k'  # can be '300' or '2k'
# =============================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

xm = load_model("transmitter", device=device)
xm.load_state_dict(torch.load("./fine_tuned_models/transmitter_state.pth", map_location=device))
model = load_model('text300M', device=device)

# Load fine-tuned weights
model.load_state_dict(torch.load(f'./model_ckpts/{ckpt}', map_location=device)['model_state_dict'])

diffusion = diffusion_from_config(load_config('diffusion'))

batch_size = 1
guidance_scale = 20.0

test_uids = pickle.load(open(f'../example_material/test_uids_{test_type}.pkl', 'rb'))
captions = pd.read_csv('../example_material/Cap3D_automated_Objaverse.csv', header=None)

outdir = f'./shapE_inference/{save_name}'
os.makedirs(outdir, exist_ok=True)

print('start generation')

prompt = "A futuristic car"
latents = sample_latents(
    batch_size=batch_size,
    model=model,
    diffusion=diffusion,
    guidance_scale=guidance_scale,
    model_kwargs=dict(texts=[prompt] * batch_size),
    progress=True,
    clip_denoised=True,
    use_fp16=True,
    use_karras=True,
    karras_steps=64,
    sigma_min=1e-3,
    sigma_max=160,
    s_churn=0,
)

with torch.no_grad():
    size = 512
    gen_mesh = decode_latent_mesh(xm, latents).tri_mesh()
    save_path = os.path.join(outdir, f'{save_name}.ply')
    with open(save_path, 'wb') as f:
        gen_mesh.write_ply(f)

print(f"Generation complete. Mesh saved to {save_path}")

"""**DEFINITELY RUN THIS CELL**"""

!pip install gradio

"""Gradio Website v1.0"""

# -------------------------
# üß† Imports and Setup
# -------------------------
import torch
import os
import gradio as gr
import tempfile

from shap_e.models.download import load_model, load_config
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.diffusion.sample import sample_latents
from shap_e.util.notebooks import (
    decode_latent_mesh,
    create_pan_cameras,
    decode_latent_images,
)

# -------------------------
# üñ•Ô∏è Device Setup
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# üîß Load Fine-Tuned Models
# -------------------------

print("‚úÖ Loading models...")
text_model = load_model('text300M', device=device)
ckpt = "shapE_finetuned_with_825kdata.pth"
# Load fine-tuned weights
text_model.load_state_dict(torch.load(f'./model_ckpts/{ckpt}', map_location=device)['model_state_dict'])

transmitter = load_model("transmitter", device=device)
transmitter.load_state_dict(torch.load("./fine_tuned_models/transmitter_state.pth", map_location=device))
diffusion = diffusion_from_config(load_config("diffusion"))

# -------------------------
# ‚ú® Mesh + GIF Generation Function
# -------------------------
def generate_mesh_and_gifs(prompt, batch_size):
    output_dir = tempfile.mkdtemp()
    ply_paths = []
    gif_paths = []

    latents = sample_latents(
        batch_size=batch_size,
        model=text_model,
        diffusion=diffusion,
        guidance_scale=20.0,
        model_kwargs=dict(texts=[prompt] * batch_size),
        progress=True,
        clip_denoised=True,
        use_fp16=True,
        use_karras=True,
        karras_steps=64,
        sigma_min=1e-3,
        sigma_max=160,
        s_churn=0,
    )

    for i, latent in enumerate(latents):
        # Save .ply mesh
        ply_path = os.path.join(output_dir, f"{prompt.replace(' ', '_')}_{i}.ply")
        with open(ply_path, "wb") as f:
            decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)
        ply_paths.append(ply_path)

        # Save high-res GIF
        cameras = create_pan_cameras(size=256, device=device)
        images = decode_latent_images(transmitter, latent, cameras, rendering_mode="nerf")

        gif_path = os.path.join(output_dir, f"{prompt.replace(' ', '_')}_{i}.gif")
        images[0].save(gif_path, save_all=True, append_images=images[1:], duration=100, loop=0)
        gif_paths.append(gif_path)

    return gif_paths, ply_paths

# -------------------------
# üåê Gradio UI
# -------------------------
iface = gr.Interface(
    fn=generate_mesh_and_gifs,
    inputs=[
        gr.Textbox(label="Prompt", placeholder="e.g. a realistic fantasy sword with intricate design"),
        gr.Slider(minimum=1, maximum=4, step=1, value=1, label="Batch Size (Number of Meshes)")
    ],
    outputs=[
        gr.Gallery(label="üåÄ High-Res Rotating GIFs", columns=2, height=320),
        gr.File(label="üì¶ Download .PLY Mesh Files", file_types=[".ply"], file_count="multiple"),
    ],
    title="Shap-E Fine Tuned 3D Mesh Generator (GIF + Mesh Download)",
    description="Generate beautiful high-res 3D mesh renders as GIFs and download the .ply files using your fine-tuned Shap-E model. This model has been fine tuned Cap3D style using Objaverse dataset.",
)

iface.launch(debug=True)

# -------------------------
# üß† Imports and Setup
# -------------------------
import torch
import os
import gradio as gr
import tempfile

from shap_e.models.download import load_model, load_config
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.diffusion.sample import sample_latents
from shap_e.util.notebooks import (
    decode_latent_mesh,
    create_pan_cameras,
    decode_latent_images,
)

# -------------------------
# üñ•Ô∏è Device Setup
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# üîß Load Base + Fine-Tuned Models
# -------------------------

print("‚úÖ Loading models...")

# Load base model
base_text_model = load_model('text300M', device=device)
base_text_model.load_state_dict(torch.load('./fine_tuned_models/text300M_state.pth', map_location=device))

# Load fine-tuned model
fine_tuned_text_model = load_model('text300M', device=device)
fine_tuned_text_model.load_state_dict(torch.load('./model_ckpts/shapE_finetuned_with_825kdata.pth', map_location=device)['model_state_dict'])

# Load transmitter + diffusion
transmitter = load_model("transmitter", device=device)
transmitter.load_state_dict(torch.load("./fine_tuned_models/transmitter_state.pth", map_location=device))
diffusion = diffusion_from_config(load_config("diffusion"))

# -------------------------
# ‚ú® Mesh + GIF Generation Function
# -------------------------
def generate_mesh_and_gifs(prompt, batch_size):
    output_dir = tempfile.mkdtemp()

    gif_paths_base = []
    gif_paths_finetuned = []

    ply_paths_base = []
    ply_paths_finetuned = []

    def generate_for_model(model, tag):
        latents = sample_latents(
            batch_size=batch_size,
            model=model,
            diffusion=diffusion,
            guidance_scale=20.0,
            model_kwargs=dict(texts=[prompt] * batch_size),
            progress=True,
            clip_denoised=True,
            use_fp16=True,
            use_karras=True,
            karras_steps=64,
            sigma_min=1e-3,
            sigma_max=160,
            s_churn=0,
        )

        gifs = []
        plys = []

        for i, latent in enumerate(latents):
            name_prefix = f"{prompt.replace(' ', '_')}_{tag}_{i}"
            # Save .ply
            ply_path = os.path.join(output_dir, f"{name_prefix}.ply")
            with open(ply_path, "wb") as f:
                decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)
            plys.append(ply_path)

            # Save GIF
            cameras = create_pan_cameras(size=256, device=device)
            images = decode_latent_images(transmitter, latent, cameras, rendering_mode="nerf")
            gif_path = os.path.join(output_dir, f"{name_prefix}.gif")
            images[0].save(gif_path, save_all=True, append_images=images[1:], duration=100, loop=0)
            gifs.append(gif_path)

        return gifs, plys

    gif_paths_base, ply_paths_base = generate_for_model(base_text_model, "base")
    gif_paths_finetuned, ply_paths_finetuned = generate_for_model(fine_tuned_text_model, "fine_tuned")

    # Return both sets
    return (
        gif_paths_base + gif_paths_finetuned,
        ply_paths_base + ply_paths_finetuned
    )

# -------------------------
# üåê Gradio UI
# -------------------------
iface = gr.Interface(
    fn=generate_mesh_and_gifs,
    inputs=[
        gr.Textbox(label="Prompt", placeholder="e.g. a realistic fantasy sword with intricate design"),
        gr.Slider(minimum=1, maximum=2, step=1, value=1, label="Batch Size (Number of Meshes per Model)")
    ],
    outputs=[
        gr.Gallery(label="üåÄ Base vs Fine-Tuned: High-Res GIFs", columns=4, height=320),
        gr.File(label="üì¶ Download All .PLY Meshes", file_types=[".ply"], file_count="multiple"),
    ],
    title="Shap-E Fine Tuned 3D Mesh Generator (GIF + Mesh Download)",
    description="Generate beautiful high-res 3D mesh renders as GIFs and download the .ply files using your fine-tuned Shap-E model. This model has been fine tuned Cap3D style using Objaverse dataset.",
    )

iface.launch(debug=True)

"""**VERSION 3.0**"""

# -------------------------
# üß† Imports and Setup
# -------------------------
import torch
import os
import gradio as gr
import tempfile
from PIL import Image

from shap_e.models.download import load_model, load_config
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.diffusion.sample import sample_latents
from shap_e.util.notebooks import (
    decode_latent_mesh,
    create_pan_cameras,
    decode_latent_images,
)

# -------------------------
# üñ•Ô∏è Device Setup
# -------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------
# üîß Load Models
# -------------------------
print("‚úÖ Loading models...")

base_text_model = load_model('text300M', device=device)
base_text_model.load_state_dict(torch.load('./fine_tuned_models/text300M_state.pth', map_location=device))

fine_tuned_text_model = load_model('text300M', device=device)
fine_tuned_text_model.load_state_dict(torch.load('./model_ckpts/shapE_finetuned_with_825kdata.pth', map_location=device)['model_state_dict'])

transmitter = load_model("transmitter", device=device)
transmitter.load_state_dict(torch.load("./fine_tuned_models/transmitter_state.pth", map_location=device))

diffusion = diffusion_from_config(load_config("diffusion"))

# -------------------------
# ‚ú® Mesh + GIF Generator
# -------------------------
def generate_mesh_and_gifs(prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max):
    output_dir = tempfile.mkdtemp()

    def generate_for_model(model, tag):
        latents = sample_latents(
            batch_size=batch_size,
            model=model,
            diffusion=diffusion,
            guidance_scale=guidance_scale,
            model_kwargs=dict(texts=[prompt] * batch_size),
            progress=True,
            clip_denoised=True,
            use_fp16=True,
            use_karras=True,
            karras_steps=karras_steps,
            sigma_min=sigma_min,
            sigma_max=sigma_max,
            s_churn=0,
        )

        gifs = []
        plys = []

        for i, latent in enumerate(latents):
            name_prefix = f"{prompt.replace(' ', '_')}_{tag}_{i}"

            ply_path = os.path.join(output_dir, f"{name_prefix}.ply")
            with open(ply_path, "wb") as f:
                decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)
            plys.append(ply_path)

            cameras = create_pan_cameras(size=256, device=device)
            images = decode_latent_images(transmitter, latent, cameras, rendering_mode="nerf")

            gif_path = os.path.join(output_dir, f"{name_prefix}.gif")

            if tag == "base":
                images = [img.convert("P", palette=Image.ADAPTIVE, colors=64) for img in images]
                images[0].save(
                    gif_path,
                    save_all=True,
                    append_images=images[1:],
                    duration=200,
                    loop=0,
                    optimize=True,
                    disposal=2
                )
            else:
                images[0].save(
                    gif_path,
                    save_all=True,
                    append_images=images[1:],
                    duration=200,
                    loop=0,
                    optimize=False
                )

            gifs.append(gif_path)

        return gifs, plys

    gif_paths_base, ply_paths_base = generate_for_model(base_text_model, "base")
    gif_paths_finetuned, ply_paths_finetuned = generate_for_model(fine_tuned_text_model, "fine_tuned")

    return (
        [gr.update(value=gif_paths_base, label="Base Model GIFs"), gr.update(value=gif_paths_finetuned, label="Fine-Tuned Model GIFs")],
        ply_paths_base + ply_paths_finetuned
    )

# -------------------------
# üåê Gradio UI
# -------------------------
with gr.Blocks(title="Shap-E Fine Tuned Viewer") as iface:
    gr.Markdown("""
    # üî¨ Shap-E Fine Tuned 3D Mesh Generator
    Generate high-res 3D meshes from prompts. Compare base vs fine-tuned Shap-E model.
    """)

    with gr.Row():
        prompt = gr.Textbox(label="Prompt", placeholder="e.g. a realistic fantasy sword")
        batch_size = gr.Slider(minimum=1, maximum=2, value=1, step=1, label="Batch Size")

    with gr.Row():
        karras_steps = gr.Slider(minimum=32, maximum=128, value=64, step=8, label="Karras Steps")
        guidance_scale = gr.Slider(minimum=1.0, maximum=30.0, value=20.0, step=1.0, label="Guidance Scale")

    with gr.Row():
        sigma_min = gr.Slider(minimum=1e-4, maximum=1e-2, value=1e-3, step=1e-4, label="Sigma Min")
        sigma_max = gr.Slider(minimum=10, maximum=200, value=160, step=10, label="Sigma Max")

    generate_button = gr.Button("Generate 3D Meshes + GIFs")
    error_box = gr.Textbox(label="Errors", visible=False)

    with gr.Row():
        with gr.Column():
            gallery_base = gr.Gallery(label="Base Model GIFs", show_label=True, columns=2, height=320)
        with gr.Column():
            gallery_finetuned = gr.Gallery(label="Fine-Tuned Model GIFs", show_label=True, columns=2, height=320)

    file_output = gr.Files(label="Download All Meshes")

    def wrapper(prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max):
        try:
            (galleries, ply_paths) = generate_mesh_and_gifs(
                prompt, batch_size, int(karras_steps), float(guidance_scale), float(sigma_min), float(sigma_max)
            )
            return galleries[0], galleries[1], ply_paths, gr.update(visible=False)
        except Exception as e:
            return [], [], [], gr.update(value=str(e), visible=True)

    generate_button.click(
        fn=wrapper,
        inputs=[prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max],
        outputs=[gallery_base, gallery_finetuned, file_output, error_box],
    )

iface.launch(debug=True)