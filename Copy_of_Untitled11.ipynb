{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a0c6b59410b4c37ad16a9a23d6a72d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7a99860e9824d34a0ee64d8e8a9c8fa",
              "IPY_MODEL_d3e41af4ca2a45e9a5d8220c768a02e9",
              "IPY_MODEL_7faa230980fc40d9b48e92ac22099f89"
            ],
            "layout": "IPY_MODEL_f2c972dc13594747ad29308aa82464f0"
          }
        },
        "c7a99860e9824d34a0ee64d8e8a9c8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12095ddd2500434fbfae6253e159946b",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d193b2de0a485caf97b071dc159db2",
            "value": "100%"
          }
        },
        "d3e41af4ca2a45e9a5d8220c768a02e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed65ea25b50342eca53cf17563519cbe",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6810b9ebb7434665bf2ac061b54a840e",
            "value": 64
          }
        },
        "7faa230980fc40d9b48e92ac22099f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba195124f9a4cae9eb222f624739f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_69a69754a0eb42a5bb33887210ccc250",
            "value": " 64/64 [00:32&lt;00:00,  2.39it/s]"
          }
        },
        "f2c972dc13594747ad29308aa82464f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12095ddd2500434fbfae6253e159946b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d193b2de0a485caf97b071dc159db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed65ea25b50342eca53cf17563519cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6810b9ebb7434665bf2ac061b54a840e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ba195124f9a4cae9eb222f624739f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a69754a0eb42a5bb33887210ccc250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdd8TIedxFwr",
        "outputId": "a7ec52a4-96fa-4802-a08f-0d7304fab7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cap3D'...\n",
            "remote: Enumerating objects: 818, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 818 (delta 165), reused 159 (delta 159), pack-reused 641 (from 1)\u001b[K\n",
            "Receiving objects: 100% (818/818), 106.44 MiB | 10.20 MiB/s, done.\n",
            "Resolving deltas: 100% (464/464), done.\n",
            "Updating files: 100% (157/157), done.\n",
            "/content/Cap3D/text-to-3D/shap-e\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/crockwell/Cap3D.git\n",
        "%cd Cap3D/text-to-3D/shap-e\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zUQLo7vHFmA",
        "outputId": "2a43f316-2b1b-4477-8b24-1d40bd5a99f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e .\n",
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "7TfCTs_4xMP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d5674f-a6e9-4b9b-b0a4-ff9fdbe8061c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/Cap3D/text-to-3D/shap-e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git (from shap-e==0.0.0)\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-tqqgrtt2/clip_a990866bdd954d46a22789512687be48\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-tqqgrtt2/clip_a990866bdd954d46a22789512687be48\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (3.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (11.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (2.6.0+cu124)\n",
            "Collecting fire (from shap-e==0.0.0)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (2.32.3)\n",
            "Collecting plyfile (from shap-e==0.0.0)\n",
            "  Downloading plyfile-1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (3.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap-e==0.0.0) (2.0.2)\n",
            "Collecting blobfile (from shap-e==0.0.0)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->shap-e==0.0.0)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->shap-e==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->shap-e==0.0.0) (5.3.2)\n",
            "Collecting ftfy (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (2024.11.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->shap-e==0.0.0) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->shap-e==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->shap-e==0.0.0) (2025.1.31)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->shap-e==0.0.0) (0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->shap-e==0.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->shap-e==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->shap-e==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->shap-e==0.0.0) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->shap-e==0.0.0) (3.0.2)\n",
            "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plyfile-1.1-py3-none-any.whl (23 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip, fire\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=16a89a96fe1e3b2dcdf7cf5b118697609008fe43785c7c28c22dfdbd927b487f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7pfmu5bv/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=7182cc6bb8eed10b61090d62601a8be2c1d3b360aac4d4adcba8c12b030171fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built clip fire\n",
            "Installing collected packages: pycryptodomex, plyfile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, blobfile, nvidia-cusolver-cu12, clip, shap-e\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Running setup.py develop for shap-e\n",
            "Successfully installed blobfile-3.0.0 clip-1.0 fire-0.7.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 plyfile-1.1 pycryptodomex-3.22.0 shap-e-0.0.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown if not already installed\n",
        "!pip install -q gdown\n",
        "\n",
        "# Download the file using the file ID\n",
        "!gdown --id 1GQOZFfAMJ4parzt6Amjvy-5Wzqb5CpxC --output myfile.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip myfile.zip -d myfolder\n"
      ],
      "metadata": {
        "id": "yWFMbmLnPzr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cp -r myfolder/fineTune/model_ckpts .\n",
        "!rm -rf myfolder\n",
        "!rm myfile.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "jqkNxgrCxQAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from shap_e.models.download import load_model\n",
        "import os\n",
        "\n",
        "os.makedirs(\"fine_tuned_models\",exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load full models (only once)\n",
        "text_model = load_model(\"text300M\", device=device)\n",
        "transmitter = load_model(\"transmitter\", device=device)\n",
        "\n",
        "# Save their state_dicts\n",
        "torch.save(text_model.state_dict(), \"./fine_tuned_models/text300M_state.pth\")\n",
        "torch.save(transmitter.state_dict(), \"./fine_tuned_models/transmitter_state.pth\")\n"
      ],
      "metadata": {
        "id": "HtZP0gSF0w7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No Need to Run this Cell**"
      ],
      "metadata": {
        "id": "lIKARib_4U6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Copyright (c) 2023 Tiange Luo, tiange.cs@gmail.com\n",
        "# Last modified: September 20, 2023\n",
        "#\n",
        "# This code is licensed under the MIT License.\n",
        "# ==============================================================================\n",
        "import torch\n",
        "\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import decode_latent_mesh\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from IPython import embed\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# ==== Set configuration variables directly ====\n",
        "ckpt = 'shapE_finetuned_with_825kdata.pth'\n",
        "save_name = 'Cap3D_test1_meshes'\n",
        "test_type = '2k'  # can be '300' or '2k'\n",
        "# =============================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "xm = load_model(\"transmitter\", device=device)\n",
        "xm.load_state_dict(torch.load(\"./fine_tuned_models/transmitter_state.pth\", map_location=device))\n",
        "model = load_model('text300M', device=device)\n",
        "\n",
        "# Load fine-tuned weights\n",
        "model.load_state_dict(torch.load(f'./model_ckpts/{ckpt}', map_location=device)['model_state_dict'])\n",
        "\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))\n",
        "\n",
        "batch_size = 1\n",
        "guidance_scale = 20.0\n",
        "\n",
        "test_uids = pickle.load(open(f'../example_material/test_uids_{test_type}.pkl', 'rb'))\n",
        "captions = pd.read_csv('../example_material/Cap3D_automated_Objaverse.csv', header=None)\n",
        "\n",
        "outdir = f'./shapE_inference/{save_name}'\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "print('start generation')\n",
        "\n",
        "prompt = \"A futuristic car\"\n",
        "latents = sample_latents(\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    diffusion=diffusion,\n",
        "    guidance_scale=guidance_scale,\n",
        "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
        "    progress=True,\n",
        "    clip_denoised=True,\n",
        "    use_fp16=True,\n",
        "    use_karras=True,\n",
        "    karras_steps=64,\n",
        "    sigma_min=1e-3,\n",
        "    sigma_max=160,\n",
        "    s_churn=0,\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    size = 512\n",
        "    gen_mesh = decode_latent_mesh(xm, latents).tri_mesh()\n",
        "    save_path = os.path.join(outdir, f'{save_name}.ply')\n",
        "    with open(save_path, 'wb') as f:\n",
        "        gen_mesh.write_ply(f)\n",
        "\n",
        "print(f\"Generation complete. Mesh saved to {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "2a0c6b59410b4c37ad16a9a23d6a72d2",
            "c7a99860e9824d34a0ee64d8e8a9c8fa",
            "d3e41af4ca2a45e9a5d8220c768a02e9",
            "7faa230980fc40d9b48e92ac22099f89",
            "f2c972dc13594747ad29308aa82464f0",
            "12095ddd2500434fbfae6253e159946b",
            "e9d193b2de0a485caf97b071dc159db2",
            "ed65ea25b50342eca53cf17563519cbe",
            "6810b9ebb7434665bf2ac061b54a840e",
            "8ba195124f9a4cae9eb222f624739f8d",
            "69a69754a0eb42a5bb33887210ccc250"
          ]
        },
        "id": "sgsBGctJ0yZq",
        "outputId": "808e297b-535e-4233-f125-be198a939ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start generation\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a0c6b59410b4c37ad16a9a23d6a72d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Cap3D/text-to-3D/shap-e/shap_e/models/stf/renderer.py:279: UserWarning: exception rendering with PyTorch3D: No module named 'pytorch3d'\n",
            "  warnings.warn(f\"exception rendering with PyTorch3D: {exc}\")\n",
            "/content/Cap3D/text-to-3D/shap-e/shap_e/models/stf/renderer.py:280: UserWarning: falling back on native PyTorch renderer, which does not support full gradients\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation complete. Mesh saved to ./shapE_inference/Cap3D_test1_meshes/Cap3D_test1_meshes.ply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINITELY RUN THIS CELL**"
      ],
      "metadata": {
        "id": "2ygylUI64bWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqogiGXWAcul",
        "outputId": "301e1d82-9245-4a71-d210-34aa850f6f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m128.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio Website v1.0"
      ],
      "metadata": {
        "id": "-AMBkK7P4kGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 🧠 Imports and Setup\n",
        "# -------------------------\n",
        "import torch\n",
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.util.notebooks import (\n",
        "    decode_latent_mesh,\n",
        "    create_pan_cameras,\n",
        "    decode_latent_images,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 🖥️ Device Setup\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# 🔧 Load Fine-Tuned Models\n",
        "# -------------------------\n",
        "\n",
        "print(\"✅ Loading models...\")\n",
        "text_model = load_model('text300M', device=device)\n",
        "ckpt = \"shapE_finetuned_with_825kdata.pth\"\n",
        "# Load fine-tuned weights\n",
        "text_model.load_state_dict(torch.load(f'./model_ckpts/{ckpt}', map_location=device)['model_state_dict'])\n",
        "\n",
        "transmitter = load_model(\"transmitter\", device=device)\n",
        "transmitter.load_state_dict(torch.load(\"./fine_tuned_models/transmitter_state.pth\", map_location=device))\n",
        "diffusion = diffusion_from_config(load_config(\"diffusion\"))\n",
        "\n",
        "# -------------------------\n",
        "# ✨ Mesh + GIF Generation Function\n",
        "# -------------------------\n",
        "def generate_mesh_and_gifs(prompt, batch_size):\n",
        "    output_dir = tempfile.mkdtemp()\n",
        "    ply_paths = []\n",
        "    gif_paths = []\n",
        "\n",
        "    latents = sample_latents(\n",
        "        batch_size=batch_size,\n",
        "        model=text_model,\n",
        "        diffusion=diffusion,\n",
        "        guidance_scale=20.0,\n",
        "        model_kwargs=dict(texts=[prompt] * batch_size),\n",
        "        progress=True,\n",
        "        clip_denoised=True,\n",
        "        use_fp16=True,\n",
        "        use_karras=True,\n",
        "        karras_steps=64,\n",
        "        sigma_min=1e-3,\n",
        "        sigma_max=160,\n",
        "        s_churn=0,\n",
        "    )\n",
        "\n",
        "    for i, latent in enumerate(latents):\n",
        "        # Save .ply mesh\n",
        "        ply_path = os.path.join(output_dir, f\"{prompt.replace(' ', '_')}_{i}.ply\")\n",
        "        with open(ply_path, \"wb\") as f:\n",
        "            decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)\n",
        "        ply_paths.append(ply_path)\n",
        "\n",
        "        # Save high-res GIF\n",
        "        cameras = create_pan_cameras(size=256, device=device)\n",
        "        images = decode_latent_images(transmitter, latent, cameras, rendering_mode=\"nerf\")\n",
        "\n",
        "        gif_path = os.path.join(output_dir, f\"{prompt.replace(' ', '_')}_{i}.gif\")\n",
        "        images[0].save(gif_path, save_all=True, append_images=images[1:], duration=100, loop=0)\n",
        "        gif_paths.append(gif_path)\n",
        "\n",
        "    return gif_paths, ply_paths\n",
        "\n",
        "# -------------------------\n",
        "# 🌐 Gradio UI\n",
        "# -------------------------\n",
        "iface = gr.Interface(\n",
        "    fn=generate_mesh_and_gifs,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Prompt\", placeholder=\"e.g. a realistic fantasy sword with intricate design\"),\n",
        "        gr.Slider(minimum=1, maximum=4, step=1, value=1, label=\"Batch Size (Number of Meshes)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Gallery(label=\"🌀 High-Res Rotating GIFs\", columns=2, height=320),\n",
        "        gr.File(label=\"📦 Download .PLY Mesh Files\", file_types=[\".ply\"], file_count=\"multiple\"),\n",
        "    ],\n",
        "    title=\"Shap-E Fine Tuned 3D Mesh Generator (GIF + Mesh Download)\",\n",
        "    description=\"Generate beautiful high-res 3D mesh renders as GIFs and download the .ply files using your fine-tuned Shap-E model. This model has been fine tuned Cap3D style using Objaverse dataset.\",\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "jBNQQvCeAAzl",
        "outputId": "28e6fc47-b487-4e96-c234-3862df14c89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loading models...\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://bdef1081c5c432d122.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bdef1081c5c432d122.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://bdef1081c5c432d122.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 🧠 Imports and Setup\n",
        "# -------------------------\n",
        "import torch\n",
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.util.notebooks import (\n",
        "    decode_latent_mesh,\n",
        "    create_pan_cameras,\n",
        "    decode_latent_images,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 🖥️ Device Setup\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# 🔧 Load Base + Fine-Tuned Models\n",
        "# -------------------------\n",
        "\n",
        "print(\"✅ Loading models...\")\n",
        "\n",
        "# Load base model\n",
        "base_text_model = load_model('text300M', device=device)\n",
        "base_text_model.load_state_dict(torch.load('./fine_tuned_models/text300M_state.pth', map_location=device))\n",
        "\n",
        "# Load fine-tuned model\n",
        "fine_tuned_text_model = load_model('text300M', device=device)\n",
        "fine_tuned_text_model.load_state_dict(torch.load('./model_ckpts/shapE_finetuned_with_825kdata.pth', map_location=device)['model_state_dict'])\n",
        "\n",
        "# Load transmitter + diffusion\n",
        "transmitter = load_model(\"transmitter\", device=device)\n",
        "transmitter.load_state_dict(torch.load(\"./fine_tuned_models/transmitter_state.pth\", map_location=device))\n",
        "diffusion = diffusion_from_config(load_config(\"diffusion\"))\n",
        "\n",
        "# -------------------------\n",
        "# ✨ Mesh + GIF Generation Function\n",
        "# -------------------------\n",
        "def generate_mesh_and_gifs(prompt, batch_size):\n",
        "    output_dir = tempfile.mkdtemp()\n",
        "\n",
        "    gif_paths_base = []\n",
        "    gif_paths_finetuned = []\n",
        "\n",
        "    ply_paths_base = []\n",
        "    ply_paths_finetuned = []\n",
        "\n",
        "    def generate_for_model(model, tag):\n",
        "        latents = sample_latents(\n",
        "            batch_size=batch_size,\n",
        "            model=model,\n",
        "            diffusion=diffusion,\n",
        "            guidance_scale=20.0,\n",
        "            model_kwargs=dict(texts=[prompt] * batch_size),\n",
        "            progress=True,\n",
        "            clip_denoised=True,\n",
        "            use_fp16=True,\n",
        "            use_karras=True,\n",
        "            karras_steps=64,\n",
        "            sigma_min=1e-3,\n",
        "            sigma_max=160,\n",
        "            s_churn=0,\n",
        "        )\n",
        "\n",
        "        gifs = []\n",
        "        plys = []\n",
        "\n",
        "        for i, latent in enumerate(latents):\n",
        "            name_prefix = f\"{prompt.replace(' ', '_')}_{tag}_{i}\"\n",
        "            # Save .ply\n",
        "            ply_path = os.path.join(output_dir, f\"{name_prefix}.ply\")\n",
        "            with open(ply_path, \"wb\") as f:\n",
        "                decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)\n",
        "            plys.append(ply_path)\n",
        "\n",
        "            # Save GIF\n",
        "            cameras = create_pan_cameras(size=256, device=device)\n",
        "            images = decode_latent_images(transmitter, latent, cameras, rendering_mode=\"nerf\")\n",
        "            gif_path = os.path.join(output_dir, f\"{name_prefix}.gif\")\n",
        "            images[0].save(gif_path, save_all=True, append_images=images[1:], duration=100, loop=0)\n",
        "            gifs.append(gif_path)\n",
        "\n",
        "        return gifs, plys\n",
        "\n",
        "    gif_paths_base, ply_paths_base = generate_for_model(base_text_model, \"base\")\n",
        "    gif_paths_finetuned, ply_paths_finetuned = generate_for_model(fine_tuned_text_model, \"fine_tuned\")\n",
        "\n",
        "    # Return both sets\n",
        "    return (\n",
        "        gif_paths_base + gif_paths_finetuned,\n",
        "        ply_paths_base + ply_paths_finetuned\n",
        "    )\n",
        "\n",
        "# -------------------------\n",
        "# 🌐 Gradio UI\n",
        "# -------------------------\n",
        "iface = gr.Interface(\n",
        "    fn=generate_mesh_and_gifs,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Prompt\", placeholder=\"e.g. a realistic fantasy sword with intricate design\"),\n",
        "        gr.Slider(minimum=1, maximum=2, step=1, value=1, label=\"Batch Size (Number of Meshes per Model)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Gallery(label=\"🌀 Base vs Fine-Tuned: High-Res GIFs\", columns=4, height=320),\n",
        "        gr.File(label=\"📦 Download All .PLY Meshes\", file_types=[\".ply\"], file_count=\"multiple\"),\n",
        "    ],\n",
        "    title=\"Shap-E Fine Tuned 3D Mesh Generator (GIF + Mesh Download)\",\n",
        "    description=\"Generate beautiful high-res 3D mesh renders as GIFs and download the .ply files using your fine-tuned Shap-E model. This model has been fine tuned Cap3D style using Objaverse dataset.\",\n",
        "    )\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "Hr39DqaOPoyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VERSION 3.0**"
      ],
      "metadata": {
        "id": "2bLDbB6gR8M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 🧠 Imports and Setup\n",
        "# -------------------------\n",
        "import torch\n",
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.util.notebooks import (\n",
        "    decode_latent_mesh,\n",
        "    create_pan_cameras,\n",
        "    decode_latent_images,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 🖥️ Device Setup\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# 🔧 Load Models\n",
        "# -------------------------\n",
        "print(\"✅ Loading models...\")\n",
        "\n",
        "base_text_model = load_model('text300M', device=device)\n",
        "base_text_model.load_state_dict(torch.load('./fine_tuned_models/text300M_state.pth', map_location=device))\n",
        "\n",
        "fine_tuned_text_model = load_model('text300M', device=device)\n",
        "fine_tuned_text_model.load_state_dict(torch.load('./model_ckpts/shapE_finetuned_with_825kdata.pth', map_location=device)['model_state_dict'])\n",
        "\n",
        "transmitter = load_model(\"transmitter\", device=device)\n",
        "transmitter.load_state_dict(torch.load(\"./fine_tuned_models/transmitter_state.pth\", map_location=device))\n",
        "\n",
        "diffusion = diffusion_from_config(load_config(\"diffusion\"))\n",
        "\n",
        "# -------------------------\n",
        "# ✨ Mesh + GIF Generator\n",
        "# -------------------------\n",
        "def generate_mesh_and_gifs(prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max):\n",
        "    output_dir = tempfile.mkdtemp()\n",
        "\n",
        "    def generate_for_model(model, tag):\n",
        "        latents = sample_latents(\n",
        "            batch_size=batch_size,\n",
        "            model=model,\n",
        "            diffusion=diffusion,\n",
        "            guidance_scale=guidance_scale,\n",
        "            model_kwargs=dict(texts=[prompt] * batch_size),\n",
        "            progress=True,\n",
        "            clip_denoised=True,\n",
        "            use_fp16=True,\n",
        "            use_karras=True,\n",
        "            karras_steps=karras_steps,\n",
        "            sigma_min=sigma_min,\n",
        "            sigma_max=sigma_max,\n",
        "            s_churn=0,\n",
        "        )\n",
        "\n",
        "        gifs = []\n",
        "        plys = []\n",
        "\n",
        "        for i, latent in enumerate(latents):\n",
        "            name_prefix = f\"{prompt.replace(' ', '_')}_{tag}_{i}\"\n",
        "\n",
        "            ply_path = os.path.join(output_dir, f\"{name_prefix}.ply\")\n",
        "            with open(ply_path, \"wb\") as f:\n",
        "                decode_latent_mesh(transmitter, latent).tri_mesh().write_ply(f)\n",
        "            plys.append(ply_path)\n",
        "\n",
        "            cameras = create_pan_cameras(size=256, device=device)\n",
        "            images = decode_latent_images(transmitter, latent, cameras, rendering_mode=\"nerf\")\n",
        "\n",
        "            gif_path = os.path.join(output_dir, f\"{name_prefix}.gif\")\n",
        "\n",
        "            if tag == \"base\":\n",
        "                images = [img.convert(\"P\", palette=Image.ADAPTIVE, colors=64) for img in images]\n",
        "                images[0].save(\n",
        "                    gif_path,\n",
        "                    save_all=True,\n",
        "                    append_images=images[1:],\n",
        "                    duration=200,\n",
        "                    loop=0,\n",
        "                    optimize=True,\n",
        "                    disposal=2\n",
        "                )\n",
        "            else:\n",
        "                images[0].save(\n",
        "                    gif_path,\n",
        "                    save_all=True,\n",
        "                    append_images=images[1:],\n",
        "                    duration=200,\n",
        "                    loop=0,\n",
        "                    optimize=False\n",
        "                )\n",
        "\n",
        "            gifs.append(gif_path)\n",
        "\n",
        "        return gifs, plys\n",
        "\n",
        "    gif_paths_base, ply_paths_base = generate_for_model(base_text_model, \"base\")\n",
        "    gif_paths_finetuned, ply_paths_finetuned = generate_for_model(fine_tuned_text_model, \"fine_tuned\")\n",
        "\n",
        "    return (\n",
        "        [gr.update(value=gif_paths_base, label=\"Base Model GIFs\"), gr.update(value=gif_paths_finetuned, label=\"Fine-Tuned Model GIFs\")],\n",
        "        ply_paths_base + ply_paths_finetuned\n",
        "    )\n",
        "\n",
        "# -------------------------\n",
        "# 🌐 Gradio UI\n",
        "# -------------------------\n",
        "with gr.Blocks(title=\"Shap-E Fine Tuned Viewer\") as iface:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔬 Shap-E Fine Tuned 3D Mesh Generator\n",
        "    Generate high-res 3D meshes from prompts. Compare base vs fine-tuned Shap-E model.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Prompt\", placeholder=\"e.g. a realistic fantasy sword\")\n",
        "        batch_size = gr.Slider(minimum=1, maximum=2, value=1, step=1, label=\"Batch Size\")\n",
        "\n",
        "    with gr.Row():\n",
        "        karras_steps = gr.Slider(minimum=32, maximum=128, value=64, step=8, label=\"Karras Steps\")\n",
        "        guidance_scale = gr.Slider(minimum=1.0, maximum=30.0, value=20.0, step=1.0, label=\"Guidance Scale\")\n",
        "\n",
        "    with gr.Row():\n",
        "        sigma_min = gr.Slider(minimum=1e-4, maximum=1e-2, value=1e-3, step=1e-4, label=\"Sigma Min\")\n",
        "        sigma_max = gr.Slider(minimum=10, maximum=200, value=160, step=10, label=\"Sigma Max\")\n",
        "\n",
        "    generate_button = gr.Button(\"Generate 3D Meshes + GIFs\")\n",
        "    error_box = gr.Textbox(label=\"Errors\", visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gallery_base = gr.Gallery(label=\"Base Model GIFs\", show_label=True, columns=2, height=320)\n",
        "        with gr.Column():\n",
        "            gallery_finetuned = gr.Gallery(label=\"Fine-Tuned Model GIFs\", show_label=True, columns=2, height=320)\n",
        "\n",
        "    file_output = gr.Files(label=\"Download All Meshes\")\n",
        "\n",
        "    def wrapper(prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max):\n",
        "        try:\n",
        "            (galleries, ply_paths) = generate_mesh_and_gifs(\n",
        "                prompt, batch_size, int(karras_steps), float(guidance_scale), float(sigma_min), float(sigma_max)\n",
        "            )\n",
        "            return galleries[0], galleries[1], ply_paths, gr.update(visible=False)\n",
        "        except Exception as e:\n",
        "            return [], [], [], gr.update(value=str(e), visible=True)\n",
        "\n",
        "    generate_button.click(\n",
        "        fn=wrapper,\n",
        "        inputs=[prompt, batch_size, karras_steps, guidance_scale, sigma_min, sigma_max],\n",
        "        outputs=[gallery_base, gallery_finetuned, file_output, error_box],\n",
        "    )\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "AdwGdLy7xSVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}